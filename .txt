start new train
Namespace(apply_aspp=True, backbone='mobilenetv2', batch_size=16, conv_operator='std_conv', crop_size=320, data_dir='/media/hao/DATA/Combined_Dataset', data_list='./lists/train.txt', data_val_list='./lists/test.txt', dataset='Adobe_Image_Matting', decoder='indexnet', decoder_kernel_size=5, evaluate_only=False, exp='indexnet_matting', image_mean=array([[[0.485, 0.456, 0.406, 0.   ]]]), image_scale=0.00392156862745098, image_std=array([[[0.229, 0.224, 0.225, 1.   ]]]), index_mode='m2o', indexnet='depthwise', learning_rate=0.01, momentum=0.9, mult=100, num_epochs=30, num_workers=16, output_stride=32, print_every=10, random_seed=6, record_every=20, restore_from='model_ckpt.pth.tar', result_dir='./results', scales=[1, 1.5, 2], snapshot_dir='./snapshots', sync_bn=False, use_context=True, use_nonlinear=True, weight_decay=0.0001)
image_scale :	 0.00392156862745098
image_mean :	 [[[0.485 0.456 0.406 0.   ]]]
image_std :	 [[[0.229 0.224 0.225 1.   ]]]
scales :	 [1, 1.5, 2]
dataset :	 Adobe_Image_Matting
exp :	 indexnet_matting
data_dir :	 /media/hao/DATA/Combined_Dataset
data_list :	 ./lists/train.txt
data_val_list :	 ./lists/test.txt
restore_from :	 model_ckpt.pth.tar
snapshot_dir :	 ./snapshots
result_dir :	 ./results/indexnet_matting
random_seed :	 6
evaluate_only :	 False
output_stride :	 32
conv_operator :	 std_conv
backbone :	 mobilenetv2
decoder :	 indexnet
decoder_kernel_size :	 5
indexnet :	 depthwise
index_mode :	 m2o
use_nonlinear :	 True
use_context :	 True
apply_aspp :	 True
sync_bn :	 False
crop_size :	 320
batch_size :	 16
learning_rate :	 0.01
momentum :	 0.9
mult :	 100
num_epochs :	 30
num_workers :	 16
print_every :	 10
weight_decay :	 0.0001
record_every :	 20
==> no checkpoint found at 'model_ckpt.pth.tar'
alchemy start...
Traceback (most recent call last):
  File "./scripts/newtrain.py", line 505, in <module>
    main()
  File "./scripts/newtrain.py", line 484, in main
    train(net, train_loader, optimizer, epoch + 1, scheduler, args)
  File "./scripts/newtrain.py", line 207, in train
    for i, sample in enumerate(train_loader):
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1085, in _next_data
    return self._process_data(data)
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
    data.reraise()
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
PermissionError: Caught PermissionError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
    data = fetcher.fetch(index)
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/data/yifan/jinchao/code/gitcode/indexnet_matting/scripts/hldataset.py", line 228, in __getitem__
    image = read_image(image_name)
  File "/media/data/yifan/jinchao/code/gitcode/indexnet_matting/scripts/hldataset.py", line 223, in read_image
    img_arr = np.array(Image.open(x))
  File "/media/data/yifan/envs/anaconda3/envs/nrd_v3/lib/python3.7/site-packages/PIL/Image.py", line 2975, in open
    fp = builtins.open(filename, "rb")
PermissionError: [Errno 13] Permission denied: '/media/hao/DATA/Combined_Dataset/Training_set/merged/locked_00055_92.png'

